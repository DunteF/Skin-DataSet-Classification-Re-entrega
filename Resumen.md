

El presente trabajo se realizó con el repositorio https://github.com/2245-RN-ITBA/skin-dataset-classification. 

En un primer acercamiento se abordó el entrenamiento  de una MLP propuesto por el archivo 1_Modelo Simple en Google Collab. Mediante el entrenamiento se pusieron en práctica los contenidos de la materia lo cual representó un primer aboradaje a la implementación de un modelo de ML. Se entrenó una red de 3 capas densas lineas con funciones de activación ReLU para clasificar imagenes de enfermedades dermatológicas en 10 clases. Se realizó aumentación de datos con Albumentations, se probaron diferentes inializaciones de pesos, se aplicó dropout y batch normalization y regularización L2. 
El mayor desafío enfrentado fue el manejo de archivos en el entorno de Collab y el loggeo de los entrenamientos. La principal crítica al abordaje realizado fue la exploración acotada de alternativas, se experimentó unicamente con el porcentaje de dropout y tamaños de batch. Una crítica importante de la implementación fue limitar el número de epochs a 10, lo cual limitó el aprendizaje obtenido, sobretodo en materia de experiencia identificando overfitting. En un futuro sería interesante explorar arquitecturas diferentes y más aumentaciones de datos como por ejemplo rotación que no fue usada en el trabajo o ver el efecto de transformar las imagenes a un canal con otras escalas de color. También fue desafiante el primer acercamiento a GitHub con una borrado accidental e irrecuperable de la carpeta de loggueos en el repositorio del proyecto de Collab.

En base a los desafíos propuestos por el uso de Collab el desarollo del trabajo se siguió localmente en VSCode. Esto permitió una familiarización con entornos virtuales con Conda. Construyendo sobre las dificultades previas con el loggueo se experimento con agregar más controles, trazabilidad de archivos, excepciones y errores. En un principio se intentó realizar esto usando la iniciación de runs con "with" dentro de un "try" global para los loops del entrenamiento. Esto resultó problemático por el método de funcionamiento de with y mlflow que eran previamente desconocidos, los cuales generaban fallas en el entrenamiento que no disparaban los excepts cuando había un run abierto al iniciar el bucle.  

En total se entrenaron 18 modelos en la búsqueda de hiperparametros de la MLP y 84 modelos de CNN. La gran discrepancia se debe a una limitación del espacio de parámetros de la MLP por restricciones de tiempo de cómputo y en menor medida una pequeña componente aleatoria del muestreo aleatorio de HP. 

En general los resultados no tuvieron un accuracy impresionante, por debajo de 70% incluso con la CNN. Esto refleja la amplitud del espacio explotario del tema, lo cual es un aspecto positivo porque hay mucha posibilidad de mejor. Puntualmente con la CNN es interesante que a pesar de probar múltiples combinaciones de hiperparametros no mejoró significativamente el rendimiento. Sería interesante probar con estructuras de la CNN diferentes a las definidas en helper.py, agregar más aumentaciones del dataset y ver el máximo al cual se puede llegar con este dataset particular. Esto podría  hacerse creando una clase parametrizable para el modelo cuyas variables cambien la estructura de la red y puedan ser iteradas junto con el resto de hiperparámetros.
